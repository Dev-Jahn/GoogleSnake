{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a406397-9561-40c7-b7c0-7cfe711bff78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.9.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import gym\n",
    "from gym.envs.registration import register\n",
    "from stable_baselines3 import *\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "from gsnake.env import GoogleSnakeEnv\n",
    "from gsnake.configs import GoogleSnakeConfig\n",
    "\n",
    "register(\n",
    "    id='GoogleSnake-v1',\n",
    "    entry_point=GoogleSnakeEnv,\n",
    "    max_episode_steps=500,\n",
    ")\n",
    "\n",
    "\n",
    "class CustomCNN(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space: gym.spaces.Box, features_dim: int = 256):\n",
    "        super(CustomCNN, self).__init__(observation_space, features_dim)\n",
    "        # We assume CxHxW images (channels first)\n",
    "        # Re-ordering will be done by pre-preprocessing or wrapper\n",
    "        n_input_channels = observation_space.shape[0]\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(n_input_channels, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            n_flatten = self.cnn(\n",
    "                torch.as_tensor(observation_space.sample()[None]).float()).shape[1]\n",
    "\n",
    "        self.linear = nn.Sequential(nn.Linear(n_flatten, 64), nn.ReLU())\n",
    "        self.linear2 = nn.Sequential(nn.Linear(64, features_dim))\n",
    "\n",
    "    def forward(self, observations: torch.Tensor) -> torch.Tensor:\n",
    "        return self.linear2(self.linear(self.cnn(observations)))\n",
    "\n",
    "cnnpolicy_kwargs = dict(\n",
    "    features_extractor_class=CustomCNN,\n",
    "    features_extractor_kwargs=dict(features_dim=128),\n",
    "    normalize_images=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f3257a-6cc9-4fd8-a2eb-983e4c449a05",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdev-jahn\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/ajh50/workspace/Assignments/RL2/GoogleSnake/wandb/run-20221102_222433-1c9io7z8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dev-jahn/RL2/runs/1c9io7z8\" target=\"_blank\">PPO_MLP_time_nch_10M</a></strong> to <a href=\"https://wandb.ai/dev-jahn/RL2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e26a41fc768462d86e332f74567a931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>rollout/ep_len_mean</td><td>▁▂▃▂▃▄▅▄▅▆▆▆▇▆█▇▄▅▆▅▅▄▄▄▄▃▃▄▄▃▄▄▅▄▄▄▃▄▄▄</td></tr><tr><td>rollout/ep_rew_mean</td><td>▁▁▁▂▃▂▂▃▄▃▃▄▃▄▃▄▅▅▄▅▄▆▅▆▆▇▆▇▇▇▇▇▆▇▇▇████</td></tr><tr><td>time/fps</td><td>█▃▁▁▂▂▂▂▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▃▄▄▄▄▄▄▄▃</td></tr><tr><td>train/approx_kl</td><td>▂▄▃▃▂▃▄▆▃█▃▄▄▆▇▅▃▃▅▃▅▂▁▆▂▂▃▄▁▃▃▂▃▂▂▁▂▂▂▁</td></tr><tr><td>train/clip_fraction</td><td>▆█▇▆▄▄▃▄▂▄▂▃▂▂▁▃▁▁▂▂▂▁▁▂▂▂▂▂▁▂▂▂▁▁▁▁▂▂▂▁</td></tr><tr><td>train/clip_range</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/entropy_loss</td><td>▁▂▄▅▆▇▇▇████████████████████████████████</td></tr><tr><td>train/explained_variance</td><td>▁▂▂▃▄▅▆▇▇▇▆▇▇▆▇██▇██▇▇▇█▇▇▇▇███▇███▇████</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▅▄▂▇▄▂▃▃▄▅▁▁▃▁▁▁▅▁▄▂▂▄▃▂▂▃▂▂▂▃▃▃▂▂▃▂▃▃▃</td></tr><tr><td>train/policy_gradient_loss</td><td>▁▂▄▅▇▇▆▆▇▆█▅▆▆█▇▇▇▇▆▆▇▇▆▆▆▆▅▇▆▅▆▆▆▆▅▅▅▅▆</td></tr><tr><td>train/value_loss</td><td>██▆▅▅▄▃▃▂▂▂▂▁▃▁▁▁▂▁▂▂▂▃▂▃▃▂▂▂▂▃▃▂▃▃▄▂▃▄▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>10014720</td></tr><tr><td>rollout/ep_len_mean</td><td>67.96</td></tr><tr><td>rollout/ep_rew_mean</td><td>186.21001</td></tr><tr><td>time/fps</td><td>1277.0</td></tr><tr><td>train/approx_kl</td><td>0.0079</td></tr><tr><td>train/clip_fraction</td><td>0.03755</td></tr><tr><td>train/clip_range</td><td>0.2</td></tr><tr><td>train/entropy_loss</td><td>-0.08471</td></tr><tr><td>train/explained_variance</td><td>0.74159</td></tr><tr><td>train/learning_rate</td><td>0.0003</td></tr><tr><td>train/loss</td><td>160.64726</td></tr><tr><td>train/policy_gradient_loss</td><td>-0.00553</td></tr><tr><td>train/value_loss</td><td>403.30536</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">PPO_MLP_time_nch_10M</strong>: <a href=\"https://wandb.ai/dev-jahn/RL2/runs/1c9io7z8\" target=\"_blank\">https://wandb.ai/dev-jahn/RL2/runs/1c9io7z8</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221102_222433-1c9io7z8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = 'PPO_MLP_time_nch_10M'\n",
    "\n",
    "config = GoogleSnakeConfig(\n",
    "    # reward_mode='basic',\n",
    "    multi_channel=True,\n",
    "    reward_mode='time_constrained',\n",
    "    reward_scale=1,\n",
    "    n_foods=3\n",
    ")\n",
    "run = wandb.init(\n",
    "    job_type='train', config=config.__dict__,\n",
    "    project='RL2',\n",
    "    tags=[name.split('_')[0], 'gsnake'],\n",
    "    name=name,\n",
    "    sync_tensorboard=True,\n",
    "    monitor_gym='False'\n",
    ")\n",
    "# Parallel environments\n",
    "env = make_vec_env(\"GoogleSnake-v1\", n_envs=10, env_kwargs={'config':config})\n",
    "policy_kwargs = {'normalize_images':False}\n",
    "model = PPO(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=0, tensorboard_log=f'runs/{run.id}')\n",
    "# model = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=f'runs/{run.id}')\n",
    "\n",
    "model.learn(total_timesteps=10_000_000, callback=WandbCallback(verbose=2), progress_bar=True)\n",
    "run.finish()\n",
    "\n",
    "model.save(f'{name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431697c7-7f01-4246-985d-98a0b1fb59d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/ajh50/workspace/Assignments/RL2/GoogleSnake/wandb/run-20221103_004001-1c9io7z8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href=\"https://wandb.ai/dev-jahn/RL2/runs/1c9io7z8\" target=\"_blank\">PPO_MLP_time_nch_10M</a></strong> to <a href=\"https://wandb.ai/dev-jahn/RL2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1243e47c0fa84ca19499371c97bee5fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# resume\n",
    "model = PPO.load(f'{name}.pt', env=env, device='cuda')\n",
    "run = wandb.init(\n",
    "    resume='must',\n",
    "    id='1c9io7z8',\n",
    "    job_type='train', config=config.__dict__,\n",
    "    project='RL2',\n",
    "    tags=[name.split('_')[0], 'gsnake'],\n",
    "    name=name,\n",
    "    sync_tensorboard=True,\n",
    "    monitor_gym='False'\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=40_000_000, callback=WandbCallback(verbose=2), progress_bar=True, reset_num_timesteps=False)\n",
    "model.save(f'{name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b2c960c-291a-4d7e-a2b2-98a64b02afba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/ajh50/workspace/Assignments/RL2/GoogleSnake/wandb/run-20221102_214839-3gvdkl7e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dev-jahn/RL2/runs/3gvdkl7e\" target=\"_blank\">PPO_CNN_time_nch</a></strong> to <a href=\"https://wandb.ai/dev-jahn/RL2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374e269b07aa4028bacbcdbc4093dcaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>rollout/ep_len_mean</td><td>▆▅▆██▄▆█▃▄▄▃▄▂▃▃▄▂▁▂▄▁▄▁▅▅▇▃▅█▄▅▄▂▄▅▃▅▅▃</td></tr><tr><td>rollout/ep_rew_mean</td><td>▃▄▆▃▇▄▄▅▆▂▅▃█▄▇▄▁▅▂▄▅▅▃▃▅▆▅▆▄▅▇▁▃▄▇█▆▇▄▂</td></tr><tr><td>time/fps</td><td>█▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/approx_kl</td><td>▂▁▁▂▂▂▃▄▄▅▄▄▄▄▄▅▆▆▅▇▅▆█▆▆█▆▇▆▆▆▆▆▆▇▆▆▇▇▆</td></tr><tr><td>train/clip_fraction</td><td>▂▂▁▃▂▂▃▄▅▅▄▄▄▄▅▅▆▆▅▇▅▇▇▆▇█▇▇▆▇▆▆▇▇▇▇▆▇▇▇</td></tr><tr><td>train/clip_range</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/entropy_loss</td><td>▁▁▁▁▂▂▂▂▃▃▄▄▅▅▆▆▇▇█▇▆▆▆▅▆▅▅▅▅▆▆▆▆▆▆▆▆▆▆▇</td></tr><tr><td>train/explained_variance</td><td>█▇▆██▆▄▇▅▅▄▃▃▃▁▂▃▃▄▁▃▄▂▄▄▃▃▃▇▅▇▄▃▄▆▄▆▄▇▃</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>▁▂▃▂▂▂▁▂▁▂▂▁▂▂▂▂▂▂▁▂▃▂▂▂▂▂▁▁▄▂▁▁▁▁▂▁▂▂█▂</td></tr><tr><td>train/policy_gradient_loss</td><td>▁▄▃▃▃▂▄▂▃▄▄▄▄▅▄▁▆▅▄▇▅▃█▅▆▆▆▆▆▅▇▄▄▇▇▇▄▅▅▇</td></tr><tr><td>train/value_loss</td><td>█▄▂▂▂▁▁▂▁▁▂▁▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▂▁▁▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>1003520</td></tr><tr><td>rollout/ep_len_mean</td><td>19.23</td></tr><tr><td>rollout/ep_rew_mean</td><td>-0.79</td></tr><tr><td>time/fps</td><td>1078.0</td></tr><tr><td>train/approx_kl</td><td>0.01234</td></tr><tr><td>train/clip_fraction</td><td>0.14059</td></tr><tr><td>train/clip_range</td><td>0.2</td></tr><tr><td>train/entropy_loss</td><td>-0.96023</td></tr><tr><td>train/explained_variance</td><td>-0.17357</td></tr><tr><td>train/learning_rate</td><td>0.0003</td></tr><tr><td>train/loss</td><td>41.08871</td></tr><tr><td>train/policy_gradient_loss</td><td>0.00121</td></tr><tr><td>train/value_loss</td><td>172.40005</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">PPO_CNN_time_nch</strong>: <a href=\"https://wandb.ai/dev-jahn/RL2/runs/3gvdkl7e\" target=\"_blank\">https://wandb.ai/dev-jahn/RL2/runs/3gvdkl7e</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221102_214839-3gvdkl7e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "config = GoogleSnakeConfig(\n",
    "    multi_channel=True,\n",
    "    # reward_mode='basic',\n",
    "    reward_mode='time_constrained',\n",
    "    reward_scale=1,\n",
    "    n_foods=3\n",
    ")\n",
    "name = 'PPO_CNN_time_nch'\n",
    "run = wandb.init(\n",
    "    job_type='train', config=config.__dict__,\n",
    "    project='RL2',\n",
    "    tags=[name.split('_')[0], 'gsnake'],\n",
    "    name=name,\n",
    "    sync_tensorboard=True,\n",
    "    monitor_gym='False'\n",
    ")\n",
    "# Parallel environments\n",
    "env = make_vec_env(\"GoogleSnake-v1\", n_envs=10, env_kwargs={'config':config})\n",
    "model = PPO(\n",
    "    \"CnnPolicy\",\n",
    "    env,\n",
    "    policy_kwargs=cnnpolicy_kwargs,\n",
    "    verbose=0, tensorboard_log=f'runs/{run.id}')\n",
    "# model = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=f'runs/{run.id}')\n",
    "\n",
    "model.learn(total_timesteps=1_000_000, callback=WandbCallback(verbose=2), progress_bar=True)\n",
    "run.finish()\n",
    "\n",
    "model.save(f'{name}.pt')\n",
    "del model # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e966b3f-bbac-4307-97d3-3d1a99824715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514b6f6b3e294ee184730d4ba66dcc5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666855178333814, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/ajh50/workspace/Assignments/RL2/GoogleSnake/wandb/run-20221102_010050-1z99nugc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dev-jahn/RL2/runs/1z99nugc\" target=\"_blank\">A2C_MLP_time</a></strong> to <a href=\"https://wandb.ai/dev-jahn/RL2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdc9532fe994a87b8de1da7570b19ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>rollout/ep_len_mean</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>rollout/ep_rew_mean</td><td>▄█▄▆▆▂▄▇▆▇▅▄▃▄▃▁▁▂▂▇▇▁▄▂▄▆▆▆▅▂█▃▇▄▅▃▅█▂▃</td></tr><tr><td>time/fps</td><td>▅▃▂▂▂▁▃▂▁▂▁▁▃▄▄▆▆▆▆▆▆▆▆▇▇███████▇▇▇▇▇▇▇▆</td></tr><tr><td>train/entropy_loss</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>train/explained_variance</td><td>▂▂▂▂▂▂▂▂▂▂▂▂▅▃▂▂▄▂▂▃▂▂▁▂▂▂█▂▂▂▅▂▁▃▂▂▂▅▂▂</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/policy_loss</td><td>█▁▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂</td></tr><tr><td>train/value_loss</td><td>▃▅▁▃▁▁▃▇█▁▆▂▁▄▄▅▁▂▄▇▃▁▁▁▂▆▁▄▃▅▄▃▃▅▂▁▃▁▅▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>1000000</td></tr><tr><td>rollout/ep_len_mean</td><td>12.0</td></tr><tr><td>rollout/ep_rew_mean</td><td>-3.82</td></tr><tr><td>time/fps</td><td>4615.0</td></tr><tr><td>train/entropy_loss</td><td>-8e-05</td></tr><tr><td>train/explained_variance</td><td>0.0008</td></tr><tr><td>train/learning_rate</td><td>0.0007</td></tr><tr><td>train/policy_loss</td><td>-1e-05</td></tr><tr><td>train/value_loss</td><td>24.70985</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">A2C_MLP_time</strong>: <a href=\"https://wandb.ai/dev-jahn/RL2/runs/1z99nugc\" target=\"_blank\">https://wandb.ai/dev-jahn/RL2/runs/1z99nugc</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221102_010050-1z99nugc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = 'A2C_MLP_time'\n",
    "run = wandb.init(\n",
    "    job_type='train', config=config.__dict__,\n",
    "    project='RL2',\n",
    "    tags=[name.split('_')[0], 'gsnake'],\n",
    "    name=name,\n",
    "    sync_tensorboard=True,\n",
    "    monitor_gym='False'\n",
    ")\n",
    "# Parallel environments\n",
    "env = make_vec_env(\"GoogleSnake-v1\", n_envs=10, env_kwargs={'config':config})\n",
    "model = A2C(\"MlpPolicy\", env, verbose=0, tensorboard_log=f'runs/{run.id}')\n",
    "\n",
    "model.learn(total_timesteps=1_000_000, callback=WandbCallback(verbose=2), progress_bar=True)\n",
    "run.finish()\n",
    "\n",
    "model.save(f'{name}.pt')\n",
    "del model # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d15e710-b7a5-4a17-a764-426ed16287ba",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4c723102614e48b4b93cdd27bfe8cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666861878332687, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/ajh50/workspace/Assignments/RL2/GoogleSnake/wandb/run-20221102_010445-u1631sxk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dev-jahn/RL2/runs/u1631sxk\" target=\"_blank\">DDPG_MLP_time</a></strong> to <a href=\"https://wandb.ai/dev-jahn/RL2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AssertionError",
     "evalue": "The algorithm only supports <class 'gym.spaces.box.Box'> as action spaces but Discrete(3) was provided",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Parallel environments\u001b[39;00m\n\u001b[1;32m     11\u001b[0m env \u001b[38;5;241m=\u001b[39m make_vec_env(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGoogleSnake-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m, n_envs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, env_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m:config})\n\u001b[0;32m---> 12\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDDPG\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMlpPolicy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mruns/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrun\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mlearn(total_timesteps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1_000_000\u001b[39m, callback\u001b[38;5;241m=\u001b[39mWandbCallback(verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m), progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m run\u001b[38;5;241m.\u001b[39mfinish()\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.9/site-packages/stable_baselines3/ddpg/ddpg.py:85\u001b[0m, in \u001b[0;36mDDPG.__init__\u001b[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, tensorboard_log, create_eval_env, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     62\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, Type[TD3Policy]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m     _init_setup_model: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     83\u001b[0m ):\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtau\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgradient_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_eval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_eval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Remove all tricks from TD3 to obtain DDPG:\u001b[39;49;00m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# we still need to specify target_policy_noise > 0 to avoid errors\u001b[39;49;00m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_delay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_noise_clip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_policy_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_init_setup_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;66;03m# Use only one critic\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_critics\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_kwargs:\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.9/site-packages/stable_baselines3/td3/td3.py:103\u001b[0m, in \u001b[0;36mTD3.__init__\u001b[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, policy_delay, target_policy_noise, target_noise_clip, tensorboard_log, create_eval_env, policy_kwargs, verbose, seed, device, _init_setup_model)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     77\u001b[0m     policy: Union[\u001b[38;5;28mstr\u001b[39m, Type[TD3Policy]],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     _init_setup_model: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    101\u001b[0m ):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbuffer_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgradient_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreplay_buffer_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_eval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_eval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_support\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimize_memory_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgym\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspaces\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBox\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupport_multi_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_delay \u001b[38;5;241m=\u001b[39m policy_delay\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_noise_clip \u001b[38;5;241m=\u001b[39m target_noise_clip\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.9/site-packages/stable_baselines3/common/off_policy_algorithm.py:111\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.__init__\u001b[0;34m(self, policy, env, learning_rate, buffer_size, learning_starts, batch_size, tau, gamma, train_freq, gradient_steps, action_noise, replay_buffer_class, replay_buffer_kwargs, optimize_memory_usage, policy_kwargs, tensorboard_log, verbose, device, support_multi_env, create_eval_env, monitor_wrapper, seed, use_sde, sde_sample_freq, use_sde_at_warmup, sde_support, supported_action_spaces)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     82\u001b[0m     policy: Type[BasePolicy],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     supported_action_spaces: Optional[Tuple[gym\u001b[38;5;241m.\u001b[39mspaces\u001b[38;5;241m.\u001b[39mSpace, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ):\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtensorboard_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensorboard_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupport_multi_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupport_multi_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_eval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_eval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmonitor_wrapper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_sde\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_sde\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m        \u001b[49m\u001b[43msde_sample_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msde_sample_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m        \u001b[49m\u001b[43msupported_action_spaces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msupported_action_spaces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_size \u001b[38;5;241m=\u001b[39m buffer_size\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m batch_size\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.9/site-packages/stable_baselines3/common/base_class.py:187\u001b[0m, in \u001b[0;36mBaseAlgorithm.__init__\u001b[0;34m(self, policy, env, learning_rate, policy_kwargs, tensorboard_log, verbose, device, support_multi_env, create_eval_env, monitor_wrapper, seed, use_sde, sde_sample_freq, supported_action_spaces)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;241m=\u001b[39m env\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m supported_action_spaces \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, supported_action_spaces), (\n\u001b[1;32m    188\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe algorithm only supports \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_action_spaces\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as action spaces \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was provided\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    190\u001b[0m     )\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m support_multi_env \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_envs \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    194\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: the model does not support multiple envs; it requires \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma single vectorized environment.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    195\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: The algorithm only supports <class 'gym.spaces.box.Box'> as action spaces but Discrete(3) was provided"
     ]
    }
   ],
   "source": [
    "name = 'DDPG_MLP_time'\n",
    "run = wandb.init(\n",
    "    job_type='train', config=config.__dict__,\n",
    "    project='RL2',\n",
    "    tags=[name.split('_')[0], 'gsnake'],\n",
    "    name=name,\n",
    "    sync_tensorboard=True,\n",
    "    monitor_gym='False'\n",
    ")\n",
    "# Parallel environments\n",
    "env = make_vec_env(\"GoogleSnake-v1\", n_envs=10, env_kwargs={'config':config})\n",
    "model = DDPG(\"MlpPolicy\", env, verbose=0, tensorboard_log=f'runs/{run.id}')\n",
    "\n",
    "model.learn(total_timesteps=1_000_000, callback=WandbCallback(verbose=2), progress_bar=True)\n",
    "run.finish()\n",
    "\n",
    "model.save(f'{name}.pt')\n",
    "del model # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eac0279f-9488-4bc9-8235-a2cfc35ce58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:u1631sxk) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31294737eb7043e7bafcc57c790b4216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.018 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.040293…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">DDPG_MLP_time</strong>: <a href=\"https://wandb.ai/dev-jahn/RL2/runs/u1631sxk\" target=\"_blank\">https://wandb.ai/dev-jahn/RL2/runs/u1631sxk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221102_010445-u1631sxk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:u1631sxk). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d495a9412e69437db200361a8f53ae88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668424066665466, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/ajh50/workspace/Assignments/RL2/GoogleSnake/wandb/run-20221102_010555-1cgz88k8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dev-jahn/RL2/runs/1cgz88k8\" target=\"_blank\">DQN_MLP_time</a></strong> to <a href=\"https://wandb.ai/dev-jahn/RL2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1116f9f22ec0470f8cab26ec8aec585e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███</td></tr><tr><td>rollout/ep_len_mean</td><td>▂▂▂▂▁▁▁▁▁▁▁▁▁▁▂▁▁▃▂▅▁▁▅▁▄▄█▂▁▂▂▁▅█▁▂▅▂▁▁</td></tr><tr><td>rollout/ep_rew_mean</td><td>▇█▇▇▇▇▇▇▇▇█▇▇▇▇▇▇▆▇▃██▄▇▄▄▂▆▇▇▆▇▅▁▇█▅▆█▇</td></tr><tr><td>rollout/exploration_rate</td><td>█▇▅▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>time/fps</td><td>▅▅▄█▇▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▅▁▁▄▂▁▅▄▁▂▂▂▂▂▂▁▁█▂▁▂█▂▁▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>998910</td></tr><tr><td>rollout/ep_len_mean</td><td>35.75</td></tr><tr><td>rollout/ep_rew_mean</td><td>-15.19</td></tr><tr><td>rollout/exploration_rate</td><td>0.05</td></tr><tr><td>time/fps</td><td>2251.0</td></tr><tr><td>train/learning_rate</td><td>0.0001</td></tr><tr><td>train/loss</td><td>4.84073</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">DQN_MLP_time</strong>: <a href=\"https://wandb.ai/dev-jahn/RL2/runs/1cgz88k8\" target=\"_blank\">https://wandb.ai/dev-jahn/RL2/runs/1cgz88k8</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221102_010555-1cgz88k8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = 'DQN_MLP_time'\n",
    "run = wandb.init(\n",
    "    job_type='train', config=config.__dict__,\n",
    "    project='RL2',\n",
    "    tags=[name.split('_')[0], 'gsnake'],\n",
    "    name=name,\n",
    "    sync_tensorboard=True,\n",
    "    monitor_gym='False'\n",
    ")\n",
    "# Parallel environments\n",
    "env = make_vec_env(\"GoogleSnake-v1\", n_envs=10, env_kwargs={'config':config})\n",
    "model = DQN(\"MlpPolicy\", env, verbose=0, tensorboard_log=f'runs/{run.id}')\n",
    "\n",
    "model.learn(total_timesteps=1_000_000, callback=WandbCallback(verbose=2), progress_bar=True)\n",
    "run.finish()\n",
    "\n",
    "model.save(f'{name}.pt')\n",
    "del model # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d2721-8981-4006-99c6-82545c89b214",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'SAC_MLP_time'\n",
    "run = wandb.init(\n",
    "    job_type='train', config=config.__dict__,\n",
    "    project='RL2',\n",
    "    tags=[name.split('_')[0], 'gsnake'],\n",
    "    name=name,\n",
    "    sync_tensorboard=True,\n",
    "    monitor_gym='False'\n",
    ")\n",
    "# Parallel environments\n",
    "env = make_vec_env(\"GoogleSnake-v1\", n_envs=10, env_kwargs={'config':config})\n",
    "model = SAC(\"MlpPolicy\", env, verbose=0, tensorboard_log=f'runs/{run.id}')\n",
    "\n",
    "model.learn(total_timesteps=1_000_000, callback=WandbCallback(verbose=2), progress_bar=True)\n",
    "run.finish()\n",
    "\n",
    "model.save(f'{name}.pt')\n",
    "del model # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4117e72-02a9-4bcd-a75d-7a655f7f1bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "name = 'TD3_MLP_time'\n",
    "run = wandb.init(\n",
    "    job_type='train', config=config.__dict__,\n",
    "    project='RL2',\n",
    "    tags=[name.split('_')[0], 'gsnake'],\n",
    "    name=name,\n",
    "    sync_tensorboard=True,\n",
    "    monitor_gym='False'\n",
    ")\n",
    "# The noise objects for TD3\n",
    "env = GoogleSnakeEnv(config)\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))\n",
    "\n",
    "# Parallel environments\n",
    "env = make_vec_env(\"GoogleSnake-v1\", n_envs=10, env_kwargs={'config':config})\n",
    "model = TD3(\"MlpPolicy\", env, action_noise=action_noise, verbose=0, tensorboard_log=f'runs/{run.id}')\n",
    "\n",
    "model.learn(total_timesteps=1_000_000, callback=WandbCallback(verbose=2), progress_bar=True)\n",
    "run.finish()\n",
    "\n",
    "model.save(f'{name}.pt')\n",
    "del model # remove to demonstrate saving and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2ec302d-b199-4cf4-a1b3-948437355cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "# Human evaluation\n",
    "####################################################################\n",
    "model = PPO.load(\"PPO_MLP_time.pt\")\n",
    "config = GoogleSnakeConfig(\n",
    "    # reward_mode='basic',\n",
    "    multi_channel=True,\n",
    "    reward_mode='time_constrained',\n",
    "    reward_scale=1,\n",
    "    n_foods=3\n",
    ")\n",
    "env = GoogleSnakeEnv(config, 42, 'gui')\n",
    "obs = env.reset()\n",
    "try:\n",
    "    while True:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        env.render()\n",
    "        sleep(0.5)\n",
    "except KeyboardInterrupt:\n",
    "    print('Terminated')\n",
    "finally:\n",
    "    env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
