{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a406397-9561-40c7-b7c0-7cfe711bff78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.0 (SDL 2.0.16, Python 3.9.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import gym\n",
    "from gym.envs.registration import register\n",
    "from stable_baselines3 import *\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "\n",
    "from gsnake.env import GoogleSnakeEnv\n",
    "from gsnake.configs import GoogleSnakeConfig\n",
    "\n",
    "register(\n",
    "    id='GoogleSnake-v1',\n",
    "    entry_point=GoogleSnakeEnv,\n",
    "    max_episode_steps=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2f3257a-6cc9-4fd8-a2eb-983e4c449a05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdev-jahn\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/mnt/c/Users/ajh50/workspace/Assignments/RL2/GoogleSnake/wandb/run-20221103_022901-3rjgv6mm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/dev-jahn/RL2/runs/3rjgv6mm\" target=\"_blank\">PPO_MLP_time_nch_obsfix_50M</a></strong> to <a href=\"https://wandb.ai/dev-jahn/RL2\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbb845858ea423da8878e22f45f9854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>rollout/ep_len_mean</td><td>▁▂▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇███▇▇██▇██▇▇███</td></tr><tr><td>rollout/ep_rew_mean</td><td>▁▁▂▃▃▄▄▄▅▅▅▅▆▆▅▆▆▆▆▇▆▆▇▇▇▇▇▇▇▇▇▇▇██▇██▇█</td></tr><tr><td>time/fps</td><td>▁▂▄▆▆▇▇▇▇▇▇██████████████████▇▆▆▅▅▅▄▄▄▃▃</td></tr><tr><td>train/approx_kl</td><td>█▅▅▄▄▃▂▃▂▃▃▄▃▃▄▄▄▂▃▂▂▂▂▂▁▂▂▂▁▃▂▁▂▂▂▁▁▁▂▁</td></tr><tr><td>train/clip_fraction</td><td>█▄▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▁▁▂▂▁▁▁▁▁▂▁▁▁▁▁▂▁</td></tr><tr><td>train/clip_range</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/entropy_loss</td><td>▁▇██████████████████████████████████████</td></tr><tr><td>train/explained_variance</td><td>▁▂▄▃▅▅▅▆▇▆▇▇▆█▇█▇▆▇▆▆▆▆▇▇▇█▇▇▇▇██▇█▇█▇██</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>▁▁▂▁▂▁▃▁▂▂▂▄▂▁▁▂█▂▂▃▃▃▂▃▃▃▅▄▂▃▂▃▅▄▄▇▃▄▃▄</td></tr><tr><td>train/policy_gradient_loss</td><td>▁▆██▆▇▆▅▇▆▅▄▅▆▅▆▄▅▅▆▅▅▆▅▆▆▄▆▆▅▅▆▅▇▆▅▆▆▄▅</td></tr><tr><td>train/value_loss</td><td>▁▂▂▃▃▃▃▄▄▄▃▄▅▄▃▅▆▆▆▆▇▆▆▅▇▇▆▇▆▆▇▇▆▆▆█▇▅█▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>global_step</td><td>50012160</td></tr><tr><td>rollout/ep_len_mean</td><td>459.89001</td></tr><tr><td>rollout/ep_rew_mean</td><td>2988.29004</td></tr><tr><td>time/fps</td><td>1269.0</td></tr><tr><td>train/approx_kl</td><td>0.00398</td></tr><tr><td>train/clip_fraction</td><td>0.02447</td></tr><tr><td>train/clip_range</td><td>0.2</td></tr><tr><td>train/entropy_loss</td><td>-0.08138</td></tr><tr><td>train/explained_variance</td><td>0.90449</td></tr><tr><td>train/learning_rate</td><td>0.0003</td></tr><tr><td>train/loss</td><td>627.37451</td></tr><tr><td>train/policy_gradient_loss</td><td>-0.00429</td></tr><tr><td>train/value_loss</td><td>2204.88745</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">PPO_MLP_time_nch_obsfix_50M</strong>: <a href=\"https://wandb.ai/dev-jahn/RL2/runs/3rjgv6mm\" target=\"_blank\">https://wandb.ai/dev-jahn/RL2/runs/3rjgv6mm</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20221103_022901-3rjgv6mm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = 'PPO_MLP_time_nch_obsfix_50M'\n",
    "\n",
    "config = GoogleSnakeConfig(\n",
    "    # reward_mode='basic',\n",
    "    multi_channel=True,\n",
    "    reward_mode='time_constrained',\n",
    "    reward_scale=1,\n",
    "    n_foods=3\n",
    ")\n",
    "run = wandb.init(\n",
    "    job_type='train', config=config.__dict__,\n",
    "    project='RL2',\n",
    "    tags=[name.split('_')[0], 'gsnake'],\n",
    "    name=name,\n",
    "    sync_tensorboard=True,\n",
    "    monitor_gym='False'\n",
    ")\n",
    "# Parallel environments\n",
    "env = make_vec_env(\"GoogleSnake-v1\", n_envs=10, env_kwargs={'config':config})\n",
    "policy_kwargs = {'normalize_images':False}\n",
    "model = PPO(\n",
    "    \"MultiInputPolicy\",\n",
    "    env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    verbose=0, tensorboard_log=f'runs/{run.id}')\n",
    "# model = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=f'runs/{run.id}')\n",
    "\n",
    "model.learn(total_timesteps=50_000_000, callback=WandbCallback(verbose=2), progress_bar=True)\n",
    "run.finish()\n",
    "\n",
    "model.save(f'{name}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2ec302d-b199-4cf4-a1b3-948437355cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Terminated\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "# Human evaluation\n",
    "####################################################################\n",
    "model = PPO.load(\"PPO_MLP_time.pt\")\n",
    "config = GoogleSnakeConfig(\n",
    "    # reward_mode='basic',\n",
    "    multi_channel=True,\n",
    "    reward_mode='time_constrained',\n",
    "    reward_scale=1,\n",
    "    n_foods=3\n",
    ")\n",
    "env = GoogleSnakeEnv(config, 42, 'gui')\n",
    "obs = env.reset()\n",
    "try:\n",
    "    while True:\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, dones, info = env.step(action)\n",
    "        env.render()\n",
    "        sleep(0.5)\n",
    "except KeyboardInterrupt:\n",
    "    print('Terminated')\n",
    "finally:\n",
    "    env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "rl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
